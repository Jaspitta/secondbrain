**Design a URL shortener**

- approach
	- gather requirements
	- design API / DB
	- general design
	- deep dive / scalability

- API summary component
	- get shortened URL
		- POST /shortener
		- req: original URL
		- resp: short URL
		- needs to be fast and map 1 to 1 ideally 100M daily active users / 1B reads per day (10K per sec) / up to 5B URLs
		- implementation:
			- shorter length = 6, 62 characters (z-a+Z-A+9-0)^8 URLs 
			- human readable characters
			- how
				- why not a counter
					- cached counter (in memory cache)
					- care for concurrency -> Redis is single threaded so good
				- random generation or hashing
					- risk of collision
						- not a high risk
						- if too many collisions we can add 1 character
					- simple retry might suffice
				- remember this is not the part that needs to be super fast
				- if shortening takes .5 s or 2 s does it actually impact the service? -> Nope
	- get full url
		- GET /{shortURL}
		- res: redirect 302 (301 if you do not care about analytics because it would implement automatic browser caching)
		- if we split the analytics part we can not consider it here
		- implementation
			- very simple simple 'SELECT' should suffice
			- index the shortUrl

- high-level design
	- client -> browser
	- server
		- a basic server might not satisfy the scale requirements
			- add an api gateway
			- split redirection service and shortening service
			- might want to add an analytics service
				- will count to an in-memory
				- periodic flushing
			- add most used cache
			- shortening implemented with count require count cache
	- db
		- entity
			- shortURL
			- longUrl
			- uid -> user might want to delete
			- analytics
				- timestamp
				- used_times
				- ....
		- estimated size
			- 3 strings + 1 date + 1 int
			- at most 1kb
			- times 5B from the requirements
			- 5TB -> not great but ok for a single DB instance
		- estimated scale
			- requirement is 10k rps
			- does it spikes?
			- likely too many for 1 instance
				- possibility of replicas or sharding
				- unless we cache on the servers -> redis to cache most used
				
