{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## 2.7 Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "We want algorithms to be correct *and* fast, especially on large inputs.\n",
    "The run-time of an algorithm, implemented as a Python function,\n",
    "depends on the hardware, operating system and Python interpreter we're using,\n",
    "and whether other processes are running in the background,\n",
    "like checking for software updates.\n",
    "\n",
    "Computer scientists found a way of talking about algorithms\n",
    "that is independent of all these factors. Instead of getting bogged down with\n",
    "the exact run-times for particular input values,\n",
    "we look at how the run-times increase for ever-larger inputs. In other words,\n",
    "what we really want to know is how well (or not) an algorithm copes with growing inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### 2.7.1 Constant complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "The algorithms that best cope with growing inputs are those where\n",
    "the run-time stays roughly the same, no matter how small or large the input is.\n",
    "Such algorithms are said to have constant run-time or **constant complexity**.\n",
    "The term 'constant' doesn't mean that the run-time stays *exactly* the same\n",
    "for all inputs: it means that it doesn't grow.\n",
    "\n",
    "The **complexity** of an algorithm is the growth rate of its run-times\n",
    "as inputs get larger, when executed on the same computational environment\n",
    "(hardware, operating system, programming language and interpreter).\n",
    "The complexity is *not* about how fast the algorithm runs. For example,\n",
    "an addition algorithm that would take a whole day to find out the sum of 3 and 4\n",
    "but also takes one day (in the same environment) to add two 500-digit numbers\n",
    "would have constant complexity. A constant complexity algorithm may be slow,\n",
    "but it won't get slower for larger inputs.\n",
    "\n",
    "A simple way to see if an algorithm has constant complexity is\n",
    "to implement the algorithm in some computational environment,\n",
    "run it with ever larger inputs, measure the run-times\n",
    "and see if they remain more or less the same.\n",
    "A better approach is to determine the complexity of an algorithm\n",
    "before implementing it, from its English description.\n",
    "This prevents wasting effort in coding and testing algorithms\n",
    "that turn out to be inefficient.\n",
    "To determine the complexity of an algorithm\n",
    "we have to agree on the complexity of each operation it uses.\n",
    "\n",
    "M269 covers general-purpose algorithms, not specialised ones that\n",
    "require humongous numbers with hundreds of digits, like in cryptography.\n",
    "Even though Python supports arbitrarily large integers,\n",
    "64-bit integers and floats are large enough for our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9223372036854775807"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2**63) - 1  # largest 64-bit integer; 1 bit is for the sign"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Modern processors can do arithmetic operations on two 64-bit numbers\n",
    "with a single hardware instruction, so for M269's purposes\n",
    "we can assume that all [arithmetic operations](../02_Sequence/02_2_operations.ipynb#2.2-Arithmetic-operations)\n",
    "(except exponentiation, which I explain later) have constant complexity.\n",
    "We're *not* assuming that, for example, multiplication takes the same time as addition, but\n",
    "rather that adding 3 and 7 takes about the same time as adding 3 million and 7 million,\n",
    "and that multiplying 3 and 7 takes about the same time as multiplying 3 million and 7 million.\n",
    "\n",
    "We also assume that assignments and return statements\n",
    "have constant complexity because the work required is always the same,\n",
    "no matter how small or large the value being named or returned is.\n",
    "To be clear, we're not assuming that `x = expression` or `return expression`\n",
    "always takes the same time, as that will depend on the expression.\n",
    "However, once the expression is evaluated, assigning the value to a name or\n",
    "returning the value is a constant-time operation.\n",
    "\n",
    "If each instruction always takes some fixed amount of time,\n",
    "and the number of instructions is fixed, i.e. doesn't depend on the inputs,\n",
    "then the overall time the algorithm takes is also fixed. For example,\n",
    "floor(*x* × *y* / *z*) consists of three constant-time arithmetic operations,\n",
    "so the evaluation of the expression also takes constant time.\n",
    "Multiplication, division and computing the floor all take different times,\n",
    "but each takes a fixed time, independent of the values of its operands,\n",
    "so the overall time is also fixed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<strong>Note:</strong> An algorithm that executes a fixed number of operations, each with constant complexity, has constant complexity.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "The **Big-Theta notation** states the complexity in a concise and precise way.\n",
    "If the run-time is constant, we say that the algorithm has complexity Θ(1), or\n",
    "takes Θ(1) time, or has run-time Θ(1). The Θ(1) notation informally means\n",
    "'proportional to 1', which is a roundabout way of saying 'constant' because\n",
    "a value that is proportional to a constant (1 in this case) is also constant.\n",
    "While constant complexity could also be written as Θ(2), Θ(57) or\n",
    "with any other fixed value, the convention is to write Θ(1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### 2.7.2 Linear complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "In primary school we learned an algorithm that\n",
    "adds two arbitrarily large integers digit by digit, from right to left,\n",
    "carrying over 1 from one addition to the next when necessary.\n",
    "Since adding two digits (possibly with a carry over) takes constant time,\n",
    "the time to add two integers is directly proportional to\n",
    "the number of digits of the longest integer,\n",
    "e.g. 222 + 88 requires three digit additions, which are (from right to left)\n",
    "2 + 8, 2 + 8 + 1 carry over, and 2 + 1 carry over.\n",
    "If the number of digits of the longest integer doubles,\n",
    "then addition will take double the time.\n",
    "\n",
    "Algorithms where the run-time grows proportionally to the value or size of the\n",
    "inputs have **linear complexity** or take linear time.\n",
    "The **size** of an input is, strictly speaking, how much memory it occupies.\n",
    "Since the memory allocated to an integer may vary across\n",
    "computational environments, we use a proxy measure.\n",
    "For the purposes of M269, the size of integer *n*,\n",
    "written │*n*│, is the number of its decimal digits, e.g. │102│ = 3.\n",
    "\n",
    "If the run-time is constant, then it doesn't depend on the inputs, but\n",
    "for linear-time algorithms we have to state\n",
    "how their run-time exactly depends on the inputs. For example,\n",
    "the school algorithm for *x* + *y* is linear in max(│*x*│, │*y*│), i.e. its\n",
    "run-time is proportional to the largest size of the two integers being added.\n",
    "\n",
    "The Big-Theta notation Θ(...) indicates that an algorithm's run-time is\n",
    "proportional to ..., so we can simply state:\n",
    "the complexity of the school addition algorithm for integer inputs *x* and *y* is Θ(max(│*x*│, │*y*│)).\n",
    "\n",
    "The school addition algorithm works for arbitrary large integers,\n",
    "but in M269 we only use 64-bit integers, which have at most 19 decimal digits\n",
    "(see the largest 64-bit above). So, even if computer hardware were to use the\n",
    "school algorithm for adding *x* and *y*, the complexity would be at most\n",
    "Θ(max(│*x*│, │*y*│)) = Θ(max(19, 19)) = Θ(19) = Θ(1).\n",
    "In other words, while adding arbitrary large integers takes linear time,\n",
    "adding integers with a bounded number of digits\n",
    "(like 64 binary digits or 19 decimal digits) takes constant time,\n",
    "because the run-time won't grow beyond what it takes to process two operands\n",
    "that are the largest 64-bit numbers.\n",
    "\n",
    "Likewise, we can expect subtraction, multiplication, division and modulo to\n",
    "take longer the more digits they need to process. However, by assuming that\n",
    "we will only deal with 64-bit numbers we can treat them all as constant-time operations.\n",
    "\n",
    "Let's now consider exponentiation. (Remember that\n",
    "we [don't use negative exponents](../02_Sequence/02_2_operations.ipynb#2.2.2-On-integers) in M269.)\n",
    "For integers *x* and *y*, with *y* ≥ 0 , we have $x^y = 1×x×x×\\ldots×x$.\n",
    "Hence *x*⁰ = 1 requires zero multiplications,\n",
    "*x*¹ = 1 × *x* = *x* requires one multiplication and\n",
    "in general $x^y$ requires *y* multiplications. If each\n",
    "multiplication takes constant time and if *y* doubles in value (not size!),\n",
    "then the number of multiplications (and therefore the run-time) also doubles.\n",
    "The exponentiation algorithm is therefore linear in the value of the exponent,\n",
    "not in the number of its digits. We write that\n",
    "the complexity of $x^y$ is Θ(*y*).\n",
    "\n",
    "If the complexity of exponentiation depended on the *size* of the exponent, then we'd know\n",
    "there would be at most 19 multiplications and we could treat exponentiation as\n",
    "a constant-time operation, like we did for the other arithmetic operations.\n",
    "But since the number of multiplications depends on the *value* of the exponent,\n",
    "even if its size remains fixed, e.g. at 4 decimal digits, the number of multiplications\n",
    "(and therefore the run-time) keeps growing, e.g. from 1000 to 9999.\n",
    "\n",
    "Actually, it takes constant time to compute $x^y$ when *y* = 0,\n",
    "because no multiplication is done.\n",
    "So the complexity of the algorithm varies:\n",
    "it's constant for *y* = 0 and linear for *y* > 0.\n",
    "When the complexity is different for small inputs, we just ignore it,\n",
    "because we're only interested in how an algorithm behaves for large inputs.\n",
    "So, we keep stating that the complexity of exponentiation is linear in the\n",
    "exponent's value, even though it's constant for one small exponent.\n",
    "\n",
    "To sum up, Θ(*e*),\n",
    "where *e* is an expression involving zero or more of the input variables,\n",
    "means that the run-time is proportional to *e* for large inputs.\n",
    "(It may or not be proportional to *e* for small inputs.)\n",
    "\n",
    "Note that we assumed that multiplication takes constant time. In reality,\n",
    "as we keep multiplying with a 64-bit number *x*, at some point the intermediate\n",
    "result may not fit into 64&nbsp;bits and we can't assume that each further\n",
    "multiplication takes constant time. So, for arbitrary integers *x* and *y*,\n",
    "exponentiation by repeated multiplication actually takes more than linear complexity.\n",
    "However, complexity analysis is a back of the envelope calculation to\n",
    "approximately predict the growth of run-times, so we're entitled to make some\n",
    "simplifying assumptions, as long as we clearly state them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### 2.7.3 Mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "I wrote that *e* involves zero or more input variables because\n",
    "an algorithm's complexity either doesn't depend at all on the inputs\n",
    "(constant complexity) or depends on one or more of the inputs.\n",
    "The variables that appear in the complexity expression must always be\n",
    "some or all of the input variables, otherwise the complexity isn't defined.\n",
    "For example, if a function definition starts like this:\n",
    "\n",
    "**Function**: secret operation\\\n",
    "**Inputs**: *left*, an integer; *right*: an integer\n",
    "\n",
    "then I can't write that an algorithm for this function has complexity Θ(*x*)\n",
    "or Θ(max(*l*, *r*)) or Θ(│*y*│) because none of those variables are defined:\n",
    "they don't refer to any of the inputs. I must write\n",
    "Θ(*left*) or Θ(max(*left*, *right*)) or Θ(│*right*│) or whatever the complexity is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<strong>Note:</strong> Many texts always use the variable <em>n</em> in Big-Theta expressions,\n",
    "without making clear to what the variable refers. Don't follow their example.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Another common mistake is to confuse the size and the value of an integer.\n",
    "For example, if the complexity of $x^y$  were Θ(│*y*│), then\n",
    "it would mean that the complexity is linear in the size of the exponent.\n",
    "If that were so, $x^{44}$ would take double the time to compute as $x^{4}$,\n",
    "because │44│ = 2 and │4│ = 1, when in fact it takes 11 times longer,\n",
    "because $x^{44}$ requires 44 multiplications whereas $x^{4}$ requires four.\n",
    "The complexity of exponentiation is linear in the value (not the size!)\n",
    "of the exponent, i.e. it is Θ(*y*), not Θ(│*y*│)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "#### Exercise 2.7.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Here again is an algorithm for the circumference,\n",
    "where *radius* is the input variable and *length* is the output variable.\n",
    "\n",
    "1. let *diameter* be 2 × *radius*\n",
    "2. let *length* be π × *diameter*\n",
    "\n",
    "What is the complexity of this algorithm?\n",
    "State it in words and with Big-Theta notation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "_Write your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "[Hint](../31_Hints/Hints_02_7_01.ipynb)\n",
    "[Answer](../32_Answers/Answers_02_7_01.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "⟵ [Previous section](02_6_py_functions.ipynb) | [Up](02-introduction.ipynb) | [Next section](02_8_time.ipynb) ⟶"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
